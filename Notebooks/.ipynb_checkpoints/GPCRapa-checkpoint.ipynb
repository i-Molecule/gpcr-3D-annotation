{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id = \"MUT\"\n",
    "#PDBFile = \"/media/buianov/DATA/GPCR_challenge/APJ/dynamics/20ns/sep/name0.pdb\"\n",
    "PDBFile = \"/media/buianov/DATA/GA_article/New_script_for_mapping/test/3_cN_MUTS.pdb\"\n",
    "path_to_gpcrdb_files = \"/media/buianov/DATA/GA_article/New_script_for_mapping/Gpcrdb_files/\"\n",
    "dir_path = \"/media/buianov/DATA/GA_article/New_script_for_mapping/\"\n",
    "out_path = \"/media/buianov/DATA/GA_article/New_script_for_mapping/\"\n",
    "#mapping_pt = \"/media/buianov/DATA/GA_article/New_script_for_mapping/APJ21_mapping.csv\"\n",
    "#file_name = \"/media/buianov/DATA/GPCR_challenge/APJ/dynamics/20ns/sep/name0.pdb\"\n",
    "#pdb_id = \"APJ2\"\n",
    "one_mod_df = pd.read_csv(\"/media/buianov/DATA/GA_article/Tables/onemodal_features_dist_stats.csv\")\n",
    "bi_mod_df = pd.read_csv(\"/media/buianov/DATA/GA_article/Tables/bimodal_features_dist_stats.csv\")\n",
    "model = \"/media/buianov/DATA/GA_article/New_script_for_mapping/RF_classifier_good_model_19.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPCRdb_mapping_for_sequence(pdb_id, PDBFile, path_to_gpcrdb_files, dir_path, out_path):\n",
    "    seq_num = []\n",
    "    \n",
    "    #read initial sequence\n",
    "    with open(PDBFile, 'r') as pdb_file:\n",
    "        with open(\"{}_structure_seq.fasta\".format(pdb_id), \"w\") as m:\n",
    "            for record in SeqIO.parse(pdb_file, 'pdb-atom'):\n",
    "                print('>' + pdb_id, file = m)\n",
    "                print(record.seq, file = m)\n",
    "                \n",
    "    #read initial numeration\n",
    "    with open(PDBFile, 'r') as pdb_file:\n",
    "        for line in pdb_file:\n",
    "            if \"ATOM\" in line:\n",
    "                seq_num.append(int(line[20:31]))\n",
    "    seq_num = list(set(seq_num))\n",
    "    #align initial sequence to GPCRdb alignment\n",
    "    os.system(\"mafft --addfull {} --mapout {} > ns_aligned_to_db.fasta\".format(dir_path+pdb_id+\"_structure_seq.fasta\", path_to_gpcrdb_files+\"GPCRdb_alignment_honly.fasta\"))\n",
    "    \n",
    "    #get initial position numeration according to the alogned sequence\n",
    "    map_seq = pd.read_csv(dir_path+(pdb_id+\"_structure_seq.fasta.map\"), skiprows=1)\n",
    "    map_seq[\"original position from pdb file\"] = seq_num\n",
    "    map_seq[\"GPCRdb_numeration\"] = [pd.read_csv(path_to_gpcrdb_files+\"gpcrdb_numbers_honly.csv\")[\"Numeration\"].tolist()[int(f)-1] if f  != ' -' else \" -\" for f in map_seq[\" position in the reference alignment\"].tolist()]\n",
    "    map_seq[\"original_sequence\"] = map_seq[\"# letter\"] +map_seq[\"original position from pdb file\"].astype(\"str\")\n",
    "    map_seq.to_csv(out_path+\"{}_mapping.csv\".format(pdb_id))\n",
    "    \n",
    "    #test for invalid mapping or mutant(N1.50: 98%, D2.50: 90%, R3.50: 95%, W4.50: 97%, P5.50: 78%, P6.50: 99%, P7.50: 88% F8x50)https://pubmed.ncbi.nlm.nih.gov/24304901/\n",
    "    #conserved aa residues check\n",
    "    \n",
    "    check_map_df = map_seq[map_seq[\"GPCRdb_numeration\"].isin([\"1x50\", \"2x50\", \"3x50\", \"4x50\", \"5x50\", \"6x50\", \"7x50\", \"8x50\"])].copy()\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"1x50\"][\"# letter\"].tolist()[0] != \"N\":\n",
    "        warnings.warn(\"The amino acid residue at position 1x50 seems not to be a canonical one (N). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"2x50\"][\"# letter\"].tolist()[0] != \"D\":\n",
    "        warnings.warn(\"The amino acid residue at position 2x50 seems not to be a canonical one (D). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"3x50\"][\"# letter\"].tolist()[0] != \"R\":\n",
    "        warnings.warn(\"The amino acid residue at position 3x50 seems not to be a canonical one (R). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"4x50\"][\"# letter\"].tolist()[0] != \"W\":\n",
    "        warnings.warn(\"The amino acid residue at position 4x50 seems not to be a canonical one (W). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"5x50\"][\"# letter\"].tolist()[0] != \"P\":\n",
    "        warnings.warn(\"The amino acid residue at position 5x50 seems not to be a canonical one (P). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"6x50\"][\"# letter\"].tolist()[0] != \"P\":\n",
    "        warnings.warn(\"The amino acid residue at position 6x50 seems not to be a canonical one (P). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"7x50\"][\"# letter\"].tolist()[0] != \"P\":\n",
    "        warnings.warn(\"The amino acid residue at position 7x50 seems not to be a canonical one (P). Please re-check the mapping results!\")\n",
    "    if check_map_df[check_map_df[\"GPCRdb_numeration\"] == \"8x50\"][\"# letter\"].tolist()[0] != \"F\":\n",
    "        warnings.warn(\"The amino acid residue at position 8x50 seems not to be a canonical one (F). Please re-check the mapping results!\")\n",
    "    \n",
    "    print(out_path+\"{}_mapping.csv\".format(pdb_id))\n",
    "    \n",
    "    return map_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_feature_modif_no_c_id(PDBFile, map_df, pdb_id, one_mod_df, bi_mod_df):\n",
    "    \n",
    "    d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}#, 'HIS': 'X'}\n",
    "    inv_d = {v: k for k, v in d.items()}\n",
    "    mapping = map_df\n",
    "    map_dict = {}\n",
    "    for i in range(len(mapping[\"original_sequence\"].dropna())):\n",
    "        if mapping[\"GPCRdb_numeration\"].tolist()[i] == \"-\":\n",
    "            continue\n",
    "        map_dict[str(mapping[\"original_sequence\"].dropna().tolist()[i])] = mapping[\"GPCRdb_numeration\"].tolist()[i]\n",
    "    inv_map_dict = {v: k for k, v in map_dict.items()}\n",
    "    i=0\n",
    "    res_contact_list = [\"1x49:7x50\", \"1x53:7x53\", \"1x53:7x54\", \"2x37:2x40\", \"2x42:4x45\", \"2x43:7x53\", \"2x45:4x50\", \"2x46:2x50\", \"2x50:3x39\", \"2x50:7x49\", \"2x57:7x42\", \"3x40:6x48\", \"3x43:6x40\", \"3x43:6x41\", \"3x43:7x49\", \"3x43:7x53\", \"3x46:6x37\", \"3x46:7x53\", \"3x46:3x50\",\"3x49:3x50\", \"3x50:3x53\", \"3x50:6x37\", \"3x50:7x53\", \"3x51:5x57\", \"5x51:6x44\",\"5x55:6x41\", \"5x58:6x40\", \"5x62:6x37\", \"6x40:7x49\", \"6x44:6x48\",\"6x44:7x45\",\"6x48:7x45\", \"7x45:7x49\", \"7x50:7x55\",\"7x52:7x53\", \"7x53:8x50\", \"7x54:8x50\", \"7x54:8x51\"]\n",
    "    res_contact_tup = [(f.split(\":\")[0], f.split(\":\")[1]) for f in res_contact_list]\n",
    "    #учитываем отсутствие некоторых остатков по маппингу\n",
    "    res_contact_list_inc_map = [f for f in res_contact_list if f.split(\":\")[0] in inv_map_dict.keys() and f.split(\":\")[1] in inv_map_dict.keys()]\n",
    "    #создаем словарь с картой контактов\n",
    "    contact_dict = {}\n",
    "    for item in list(set([f.split(\":\")[0] for f in res_contact_list_inc_map])):\n",
    "            contacts = [f.split(\":\")[1] for f in res_contact_list_inc_map if f.split(\":\")[0] == item]\n",
    "            contact_dict[item] = contacts\n",
    "    #создаем словарь с картой контактов остатков\n",
    "    contact_dict_transl = {}\n",
    "    for key, value in contact_dict.items():\n",
    "            contact_dict_transl[inv_map_dict[key][1:]+\"_\"+inv_d[inv_map_dict[key][0]]] = [inv_map_dict[f][1:]+\"_\"+inv_d[inv_map_dict[f][0]] for f in value]\n",
    "    #создаем список остатков, которые образуют контакты\n",
    "    residues_inv_in_contacts_list = []\n",
    "    for item in res_contact_list_inc_map:\n",
    "            residues_inv_in_contacts_list.append(inv_map_dict[item.split(\":\")[0]][1:]+\"_\"+inv_d[inv_map_dict[item.split(\":\")[0]][0]])\n",
    "            residues_inv_in_contacts_list.append(inv_map_dict[item.split(\":\")[1]][1:]+\"_\"+inv_d[inv_map_dict[item.split(\":\")[1]][0]])\n",
    "    residues_inv_in_contacts_list = list(set(residues_inv_in_contacts_list))\n",
    "\n",
    "    if [f for f in res_contact_list if f not in res_contact_list_inc_map] != []:\n",
    "        warnings.warn(\"Those features ({}) won't be computed because of missing mapping labels in mapping file. Check and recalculate mapping file or add missing mapping labels manually.\")\n",
    "    \n",
    "    fi = open(PDBFile, 'r')\n",
    "    all_lines = fi.readlines()\n",
    "    fi.close()\n",
    "    atom_lines = [l for l in all_lines if l[0:6] == 'ATOM  ']\n",
    "    dict_coord = {} # dict to store coordinates. dict_coord[res][atom] = (x,y,z,occ)\n",
    "    atomnum_2_name = {} # map atom number to atom name, in order to find N, CA, C, O\n",
    "    contact_score = {} # dict to store final results. contact_score[ires][jres] = contact_score.\n",
    "    for line in atom_lines:\n",
    "        # retrive info from each atom line\n",
    "        atom_num = int(line[6:11].strip())\n",
    "        atom_name = line[12:16].replace(' ', '_')\n",
    "        res_name = line[17:20]\n",
    "        res_num = int(line[22:26].strip())\n",
    "        #chain_id = line[21:22]\n",
    "        x = float(line[30:38].strip())\n",
    "        y = float(line[38:46].strip())\n",
    "        z = float(line[46:54].strip())\n",
    "        occ = float(line[54:60].strip())\n",
    "        res = str(res_num) + '_' + res_name\n",
    "        atomnum_2_name[atom_num] = atom_name\n",
    "        if res_num <= 0:\n",
    "            continue\n",
    "        if res not in dict_coord:\n",
    "            dict_coord[res] = {}\n",
    "        dict_coord[res][atom_num] = (x, y, z, occ)\n",
    "    mean_coords_res = {}\n",
    "    for ires in residues_inv_in_contacts_list:\n",
    "        atom_in_ires = dict_coord[ires].keys()\n",
    "        #print(atom_in_ires)\n",
    "        coords = []\n",
    "        for iatom in atom_in_ires:\n",
    "            iatom_name = atomnum_2_name[iatom]\n",
    "            if (ires.split('_')[1]) == \"GLY\":\n",
    "                if iatom_name in ['_N__', '_C__', '_O__']:\n",
    "                        continue\n",
    "                (ix, iy, iz, iocc) = dict_coord[ires][iatom]\n",
    "                coords.append([ix, iy, iz])\n",
    "            else:\n",
    "                if iatom_name in ['_N__', '_CA_', '_C__', '_O__']:\n",
    "                        continue\n",
    "            #print(iatom)\n",
    "                (ix, iy, iz, iocc) = dict_coord[ires][iatom]\n",
    "                coords.append([ix, iy, iz])\n",
    "        #print(x_coords, Average(x_coords), y_coords, Average(y_coords), z_coords, Average(z_coords))\n",
    "        coords = np.array(coords)\n",
    "        #print(coords)\n",
    "        mean_coords = np.mean(coords, axis=0)\n",
    "        mean_coords_res[ires] = mean_coords\n",
    "    inter_df = []\n",
    "    for ires in contact_dict_transl.keys():\n",
    "        for kres in contact_dict_transl[ires]:\n",
    "            ires_num = int(ires.split('_')[0].strip())\n",
    "            kres_num = int(kres.split('_')[0].strip())\n",
    "            if abs(ires_num - kres_num) < 5:\n",
    "                icor = mean_coords_res[ires]\n",
    "                kcor = mean_coords_res[kres]\n",
    "                distance = np.linalg.norm(icor - kcor)\n",
    "                inter_df.append({\"Res_1\":d[(ires.split('_')[1])]+(ires.split('_')[0]), \"Res_2\":d[(kres.split('_')[1])]+(kres.split('_')[0]), \"{:}_{:}\".format(pdb_id, PDBFile.split(\"/\")[-1].rstrip(\".pdb\")): distance})\n",
    "            elif abs(ires_num - kres_num) > 4:\n",
    "                icor = mean_coords_res[ires]\n",
    "                kcor = mean_coords_res[kres]\n",
    "                distance = np.linalg.norm(icor - kcor)\n",
    "                inter_df.append({\"Res_1\":d[(ires.split('_')[1])]+(ires.split('_')[0]), \"Res_2\":d[(kres.split('_')[1])]+(kres.split('_')[0]), \"{:}_{:}\".format(pdb_id, PDBFile.split(\"/\")[-1].rstrip(\".pdb\")): distance})\n",
    "    inter_df = pd.DataFrame(inter_df).drop_duplicates()\n",
    "    inter_df1 = inter_df.replace(({\"Res_1\": map_dict}))\n",
    "    inter_df2 = inter_df1.replace(({\"Res_2\": map_dict}))\n",
    "    contacts_df = inter_df2[inter_df2[[\"Res_1\", \"Res_2\"]].apply(tuple, axis=1).isin(res_contact_tup)]\n",
    "    contacts_df[\"Interacting_residues\"] = [\":\".join([k,f]) for k,f in zip(contacts_df[\"Res_1\"].tolist(), contacts_df[\"Res_2\"].tolist())]\n",
    "    contacts_df = contacts_df[[\"Interacting_residues\", \"{:}_{:}\".format(pdb_id, PDBFile.split(\"/\")[-1].rstrip(\".pdb\"))]].T\n",
    "    contacts_df = contacts_df.rename(columns=contacts_df.iloc[0]).drop(contacts_df.index[0])\n",
    "    contacts_df = contacts_df[res_contact_list_inc_map]\n",
    "    \n",
    "    for cf, ft in zip(contacts_df.T[contacts_df.index[0]].values, contacts_df.columns):\n",
    "        one_mod_feat = [\"2x42:4x45\", \"2x43:7x53\", \"2x45:4x50\", \"3x50:6x37\", \"3x51:5x57\", \"6x44:6x48\", \"6x44:7x45\", \"6x48:7x45\", \"7x45:7x49\"]\n",
    "        if ft in one_mod_feat:\n",
    "            appr_mean = one_mod_df[one_mod_df[\"Feature\"] == ft][\"approx_mean\"].values[0]\n",
    "            appr_std = one_mod_df[one_mod_df[\"Feature\"] == ft][\"approx_std\"].values[0]\n",
    "            l = 1\n",
    "            while ((cf > appr_mean - appr_std*l) and (cf < appr_mean + appr_std*l)) == False:\n",
    "                l+=1\n",
    "            if l < 5 and l>3:\n",
    "                warnings.warn(\"Smth wrong with feature {}. Check the distance between common activation pathway residues visually!\".format(ft))\n",
    "            elif l>= 5:\n",
    "                raise ValueError('Ambiguous {} feature value {}. Try to check structure mapping and structure model!'.format(ft, cf))\n",
    "\n",
    "        else:\n",
    "            appr_mean_1 = bi_mod_df[bi_mod_df[\"Feature\"] == ft][\"approx_mean_1\"].values[0]\n",
    "            appr_std_1 = bi_mod_df[bi_mod_df[\"Feature\"] == ft][\"approx_std_1\"].values[0]\n",
    "            appr_mean_2 = bi_mod_df[bi_mod_df[\"Feature\"] == ft][\"approx_mean_2\"].values[0]\n",
    "            appr_std_2 = bi_mod_df[bi_mod_df[\"Feature\"] == ft][\"approx_std_2\"].values[0]\n",
    "            l = 1\n",
    "            while (((cf > appr_mean_1 - appr_std_1*l) and (cf < appr_mean_1 + appr_std_1*l)) or ((cf > appr_mean_2 - appr_std_2*l) and (cf < appr_mean_2 + appr_std_2*l))) == False:\n",
    "                 l+=1\n",
    "            if l < 5 and l>3:\n",
    "                warnings.warn(\"Smth wrong with feature {}. Check the distance between common activation pathway residues visually!\".format(ft))\n",
    "            elif l>= 5:\n",
    "                raise ValueError('Ambiguous {} feature value {}. Try to check structure mapping and structure model!'.format(ft, cf))\n",
    "\n",
    "    return contacts_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pdb_id, PDBFile, path_to_gpcrdb_files, dir_path, out_path, one_mod_df, bi_mod_df, model):\n",
    "    map_df = GPCRdb_mapping_for_sequence(pdb_id, PDBFile, path_to_gpcrdb_files, dir_path, out_path)\n",
    "    res_array = calc_dist_feature_modif_no_c_id(PDBFile, map_df, pdb_id, one_mod_df, bi_mod_df)\n",
    "    rf = joblib.load(model)\n",
    "    res = rf.predict_proba(res_array)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buianov/anaconda3/envs/pybase/lib/python3.9/site-packages/Bio/PDB/PDBParser.py:395: PDBConstructionWarning: Ignoring unrecognized record 'END' at line 5547\n",
      "  warnings.warn(\n",
      "/home/buianov/anaconda3/envs/pybase/lib/python3.9/site-packages/Bio/SeqIO/PdbIO.py:303: BiopythonParserWarning: 'HEADER' line not found; can't determine PDB ID.\n",
      "  warnings.warn(\n",
      "\n",
      "nadd = 1\n",
      "dndpre (aa) Version 7.310 alg=X, model=BLOSUM62, 2.00, -0.00, +0.10, noshift, amax=0.0\n",
      "0 thread(s)\n",
      "\n",
      "All-to-all alignment.\n",
      "  288 / 289\n",
      "\n",
      "##### writing hat3\n",
      "pairlocalalign (aa) Version 7.310 alg=Y, model=BLOSUM62, 2.00, -0.00, +0.10, noshift, amax=0.0\n",
      "0 thread(s)\n",
      "\n",
      "nadd = 1\n",
      "nthread = 0\n",
      "blosum 62 / kimura 200\n",
      "sueff_global = 0.100000\n",
      "norg = 289\n",
      "njobc = 290\n",
      "Loading 'hat3' ... \n",
      "done.\n",
      "Loading 'hat2n' (aligned sequences - new sequences) ... done.\n",
      "Loading 'hat2i' (aligned sequences) ... done.\n",
      "c / 1                    \n",
      "\n",
      "Combining ..\n",
      "   done.                      \n",
      "\n",
      "   done.                      \n",
      "\n",
      "addsingle (aa) Version 7.310 alg=A, model=BLOSUM62, 1.53, -0.00, -0.00, noshift, amax=0.0\n",
      "0 thread(s)\n",
      "\n",
      "\n",
      "To keep the alignment length, 69 letters were DELETED.\n",
      "The deleted letters are shown in the (filename).map file.\n",
      "\n",
      "Strategy:\n",
      " Multi-INS-full (Not tested.)\n",
      " ?\n",
      "\n",
      "If unsure which option to use, try 'mafft --auto input > output'.\n",
      "For more information, see 'mafft --help', 'mafft --man' and the mafft page.\n",
      "\n",
      "The default gap scoring scheme has been changed in version 7.110 (2013 Oct).\n",
      "It tends to insert more gaps into gap-rich regions than previous versions.\n",
      "To disable this change, add the --leavegappyregion option.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/buianov/DATA/GA_article/New_script_for_mapping/MUT_mapping.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1351973/2940300512.py:34: UserWarning: The amino acid residue at position 2x50 seems not to be a canonical one (D). Please re-check the mapping results!\n",
      "  warnings.warn(\"The amino acid residue at position 2x50 seems not to be a canonical one (D). Please re-check the mapping results!\")\n",
      "/tmp/ipykernel_1351973/2940300512.py:36: UserWarning: The amino acid residue at position 3x50 seems not to be a canonical one (R). Please re-check the mapping results!\n",
      "  warnings.warn(\"The amino acid residue at position 3x50 seems not to be a canonical one (R). Please re-check the mapping results!\")\n",
      "/tmp/ipykernel_1351973/2940300512.py:38: UserWarning: The amino acid residue at position 4x50 seems not to be a canonical one (W). Please re-check the mapping results!\n",
      "  warnings.warn(\"The amino acid residue at position 4x50 seems not to be a canonical one (W). Please re-check the mapping results!\")\n",
      "/home/buianov/anaconda3/envs/pybase/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/buianov/anaconda3/envs/pybase/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(pdb_id, PDBFile, path_to_gpcrdb_files, dir_path, out_path, one_mod_df, bi_mod_df, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
